{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling\n",
    "# Get Dataset\n",
    "files={\n",
    "    'CICI':'/home/irteam/jiwlgus048-dcloud-dir/MLAC/data/encoded_ConcatedCICI.csv',\n",
    "    'UNSW': '/home/irteam/jiwlgus048-dcloud-dir/MLAC/data/encoded_ConcatedUNSW.csv'\n",
    "}\n",
    "\n",
    "data = pd.read_csv(files['UNSW'])\n",
    "data=data[np.isfinite(data).all(1)] # nan값 or 무한대값을 포함하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_labels=data['new_attack_category']\n",
    "data=data.drop(labels=['unnamed_0_1','label','attack_category','new_attack_category'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance 높은 feature 삭제\n",
    "del data['ct_srv_src']\n",
    "del data['ct_srv_dst']\n",
    "del data['ct_dst_ltm']\n",
    "del data['ct_src_ltm']\n",
    "del data['ct_src_dport_ltm']\n",
    "del data['ct_dst_sport_ltm']\n",
    "del data['ct_dst_src_ltm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Models\n",
    "models = []\n",
    "models.append(('RF', RandomForestClassifier(max_depth=5, n_estimators=5, max_features=3)))    \n",
    "models.append(('CART', DecisionTreeClassifier(max_depth=5)))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('QDA', QuadraticDiscriminantAnalysis()))\n",
    "models.append(('LR', LogisticRegression(solver='lbfgs', max_iter=200)))\n",
    "models.append(('ABoost', AdaBoostClassifier()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('MLP', MLPClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=['name','acc','f1_mi','f1_ma','f1_we','recall_mi','recall_ma','recall_we']+\\\n",
    "                 ['precision_mi','precision_ma','precision_we'])\n",
    "eval_path='/home/irteam/jiwlgus048-dcloud-dir/MLAC/evaluation'\n",
    "\n",
    "confusion_path='/home/irteam/jiwlgus048-dcloud-dir/MLAC/confusion_matrix/unsw_definition'\n",
    "if os.path.isdir(confusion_path)==False:\n",
    "    os.mkdir(confusion_path)\n",
    "cnt=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(data,multiclass_labels,test_size=0.3, shuffle=True, stratify=multiclass_labels, random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix plot\n",
    "def plot_confusion_matrix(con_mat,labels,title:str,cmap=plt.cm.get_cmap('Blues'),normalize=False):\n",
    "    plt.imshow(con_mat,interpolation='nearest',cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    marks=np.arange(len(labels))\n",
    "    nlabels=[]\n",
    "    for k in range(len(con_mat)):\n",
    "        n=sum(con_mat[k])\n",
    "        nlabel='{0}(n={1})'.format(labels[k],n)\n",
    "        nlabels.append(nlabel)\n",
    "\n",
    "    plt.xticks(marks,labels,rotation=45)\n",
    "    plt.yticks(marks,nlabels)\n",
    "\n",
    "    thresh=con_mat.max()/2.\n",
    "    if normalize:\n",
    "        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):\n",
    "            plt.text(j, i, '{0}%'.format(con_mat[i, j] * 100 / n), horizontalalignment=\"center\", color=\"white\" if con_mat[i, j] > thresh else \"black\")\n",
    "    else:\n",
    "        for i, j in itertools.product(range(con_mat.shape[0]), range(con_mat.shape[1])):\n",
    "            plt.text(j, i, con_mat[i, j], horizontalalignment=\"center\", color=\"white\" if con_mat[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    #plt.show()\n",
    "    #이미지 저장\n",
    "    plt.savefig(confusion_path+'/'+title+'.png',facecolor='#eeeeee',edgecolor='blue',pad_inches=0.5)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start...RF\n",
      "모델 training 소요 시간: 18.37초\n",
      "evaluation start...\n",
      "모델 test 소요 시간: 2.74초\n",
      "name:RF,acc:0.8440017357473379,f1_score:0.8440017357473379,0.09467514623390497,0.7735733548350366,recall:0.8440017357473379,0.10159446244879847,0.8440017357473379,precision:0.8440017357473379,0.18161332882273343,0.7705391020168926\n",
      "training start...CART\n",
      "모델 training 소요 시간: 92.65초\n",
      "evaluation start...\n",
      "모델 test 소요 시간: 1.98초\n",
      "name:CART,acc:0.9754656710001771,f1_score:0.9754656710001771,0.528228318668113,0.9743179721295887,recall:0.9754656710001771,0.5352217114440825,0.9754656710001771,precision:0.9754656710001771,0.6934987189950486,0.9787895831776959\n",
      "training start...NB\n",
      "모델 training 소요 시간: 14.81초\n",
      "evaluation start...\n",
      "모델 test 소요 시간: 24.57초\n",
      "name:NB,acc:0.8458537403057024,f1_score:0.8458537403057024,0.31638452888075885,0.77885453838123,recall:0.8458537403057024,0.3883839587622054,0.8458537403057024,precision:0.8458537403057024,0.36042273861901963,0.7293135984410981\n",
      "training start...LDA\n",
      "모델 training 소요 시간: 139.50초\n",
      "evaluation start...\n",
      "모델 test 소요 시간: 2.08초\n",
      "name:LDA,acc:0.966274591443739,f1_score:0.966274591443739,0.5676325058880309,0.9714355201206397,recall:0.966274591443739,0.7731911927463031,0.966274591443739,precision:0.966274591443739,0.5349078098521932,0.9787653781757144\n",
      "training start...QDA\n",
      "모델 training 소요 시간: 57.36초\n",
      "evaluation start...\n",
      "모델 test 소요 시간: 51.45초\n",
      "name:QDA,acc:0.8466134677230753,f1_score:0.8466134677230753,0.3042984445222581,0.7793725467239682,recall:0.8466134677230753,0.3367858865517427,0.8466134677230753,precision:0.8466134677230753,0.40521115707214034,0.7594106022393747\n",
      "training start...LR\n",
      "모델 training 소요 시간: 657.85초\n",
      "evaluation start...\n",
      "모델 test 소요 시간: 1.70초\n",
      "name:LR,acc:0.9825769629558534,f1_score:0.9825769629558534,0.688607477067597,0.9818479334370438,recall:0.9825769629558534,0.6866303005406409,0.9825769629558534,precision:0.9825769629558534,0.7611172056066262,0.9827984099483897\n",
      "training start...ABoost\n",
      "모델 training 소요 시간: 1205.83초\n",
      "evaluation start...\n",
      "모델 test 소요 시간: 61.30초\n",
      "name:ABoost,acc:0.9273182838812067,f1_score:0.9273182838812067,0.2639482959829528,0.9038432813757156,recall:0.9273182838812067,0.2840832033701628,0.9273182838812067,precision:0.9273182838812067,0.25100067676683213,0.8840931826595761\n",
      "training start...KNN\n",
      "모델 training 소요 시간: 3.05초\n",
      "evaluation start...\n"
     ]
    }
   ],
   "source": [
    "for name, model in models:\n",
    "\n",
    "    model=make_pipeline(model)\n",
    "    print('training start...'+name)\n",
    "    start_time=time.time()\n",
    "    model.fit(X_train,y_train)\n",
    "    end_time=time.time()\n",
    "    \n",
    "    print(\"모델 training 소요 시간: {:.2f}초\".format(end_time - start_time))\n",
    "\n",
    "\n",
    "    #evaluation\n",
    "    \n",
    "    print('evaluation start...')\n",
    "    start_time=time.time()\n",
    "    y_pred=model.predict(X_test)\n",
    "    end_time=time.time()\n",
    "    print(\"모델 test 소요 시간: {:.2f}초\".format(end_time - start_time))\n",
    "\n",
    "    #evaluation result\n",
    "    model_eval=[]\n",
    "    model_eval.append(name)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1_mi = f1_score(y_test, y_pred,average='micro')\n",
    "    f1_ma = f1_score(y_test, y_pred,average='macro')\n",
    "    f1_we = f1_score(y_test, y_pred,average='weighted')\n",
    "    recall_mi = recall_score(y_test, y_pred, average='micro')\n",
    "    recall_ma = recall_score(y_test, y_pred, average='macro')\n",
    "    recall_we = recall_score(y_test, y_pred, average='weighted')\n",
    "    precision_mi = precision_score(y_test, y_pred, average='micro')\n",
    "    precision_ma = precision_score(y_test, y_pred, average='macro')\n",
    "    precision_we = precision_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    model_eval.append(acc)\n",
    "    model_eval.append(f1_mi)\n",
    "    model_eval.append(f1_ma)\n",
    "    model_eval.append(f1_we)\n",
    "    model_eval.append(recall_mi)\n",
    "    model_eval.append(recall_ma)\n",
    "    model_eval.append(recall_we)\n",
    "    model_eval.append(precision_mi)\n",
    "    model_eval.append(precision_ma)\n",
    "    model_eval.append(precision_we)\n",
    "\n",
    "\n",
    "    #confusion_metrics\n",
    "    confusion=metrics.confusion_matrix(y_test,y_pred)\n",
    "    plot_confusion_matrix(confusion,labels=['Benign', 'Brute Force', 'Dos', 'Fuzzers']+\\\n",
    "                          ['Generic', 'Heartbleed', 'Malware', 'Reconnaissance', 'Web Attack', 'unauthorized access'],title=name)\n",
    "\n",
    "\n",
    "    print(f'name:{name},acc:{acc},f1_score:{f1_mi},{f1_ma},{f1_we},recall:{recall_mi},{recall_ma},{recall_we},precision:{precision_mi},{precision_ma},{precision_we}')\n",
    "    df.loc[cnt]=model_eval\n",
    "\n",
    "    cnt+=1\n",
    "    \n",
    "\n",
    "df.to_csv(os.path.join(eval_path,'new_unsw.csv'),index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
